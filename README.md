### Sign Language Identification App using CNN

Engineered an AI-driven **Android application** utilizing a **Convolutional Neural Network (CNN)** architecture, specifically based on the pre-trained **VGG16** model, to identify and interpret sign language motions. The application effectively converts recognized gestures into words, thereby enhancing communication between users with hearing impairments and those unfamiliar with sign language.

**Tech Stack:** Python, TensorFlow, OpenCV, Android Studio, Java, XML, Pandas.  
